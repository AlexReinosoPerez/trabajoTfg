import streamlit as st
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import requests
import os
import gdown  # Para descargar desde Google Drive

# ğŸ“Œ ConfiguraciÃ³n para evitar problemas con asyncio en Streamlit Cloud
import asyncio
import sys
if sys.platform == "win32":
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# ğŸ“Œ Mostrar la versiÃ³n de PyTorch en Streamlit Cloud
st.write(f"âœ… PyTorch versiÃ³n en Streamlit Cloud: {torch.__version__}")

# ğŸ“Œ Clases del modelo (deben coincidir con el entrenamiento)
class_names = ["Impresionismo", "Post-Impresionismo", "Pop Art", "Renacentista"]

# ğŸ“Œ ID de Google Drive (reemplÃ¡zalo con el tuyo)
DRIVE_FILE_ID = "XXXXXXXXXXXXX"  # Reemplaza con el ID del archivo en Google Drive

# ğŸ“Œ FunciÃ³n para descargar y cargar el modelo
@st.cache_resource
def load_model():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(script_dir, "best_model.pth")

    # ğŸ“Œ Descargar el modelo si no estÃ¡ en local desde Google Drive
    if not os.path.exists(model_path):
        drive_url = f"https://drive.google.com/uc?id={DRIVE_FILE_ID}"
        try:
            st.write("ğŸ“¥ Descargando modelo desde Google Drive...")
            gdown.download(drive_url, model_path, quiet=False)
            st.write("âœ… Modelo descargado correctamente desde Google Drive.")
        except Exception as e:
            st.error(f"âš ï¸ No se pudo descargar desde Google Drive: {e}")
            st.stop()

    # ğŸ“Œ Cargar el modelo en modo seguro
    try:
        state_dict = torch.load(model_path, map_location=torch.device("cpu"), weights_only=True)
    except Exception as e:
        st.error(f"âŒ Error al cargar `best_model.pth`: {e}")
        st.stop()

    # ğŸ“Œ Imprimir claves del modelo descargado
    st.write("ğŸ“‚ ParÃ¡metros en el modelo descargado:")
    for key in state_dict.keys():
        st.write(key)

    # ğŸ“Œ Definir la arquitectura correcta
    model = models.resnet50(weights=None)
    num_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(num_features, len(class_names))
    )

    # ğŸ“Œ Intentar cargar los pesos en el modelo permitiendo capas faltantes
    try:
        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)

        # ğŸ“Œ Mostrar claves no cargadas
        if missing_keys:
            st.write("âš ï¸ Claves no cargadas:", missing_keys)
        if unexpected_keys:
            st.write("âš ï¸ Claves inesperadas en el modelo:", unexpected_keys)

    except Exception as e:
        st.error(f"âŒ Error al cargar los pesos en el modelo: {e}")
        st.stop()

    model.eval()
    return model

# ğŸ“Œ Cargar el modelo
model = load_model()

# ğŸ“Œ Transformaciones para preprocesar la imagen antes de la predicciÃ³n
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ğŸ“Œ Interfaz de Streamlit
st.title("ğŸ¨ ClasificaciÃ³n de Estilos ArtÃ­sticos")

uploaded_file = st.file_uploader("ğŸ“¤ Sube una imagen", type=["jpg", "png", "jpeg"])
image_url = st.text_input("ğŸŒ O introduce una URL de imagen:")

image = None
if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Imagen subida", use_column_width=True)

elif image_url:
    try:
        response = requests.get(image_url, timeout=10)
        image = Image.open(requests.get(image_url, stream=True).raw)
        st.image(image, caption="Imagen cargada desde URL", use_column_width=True)
    except Exception as e:
        st.error("âŒ Error al cargar la imagen desde la URL.")

# ğŸ“Œ Clasificar imagen cuando el usuario presiona el botÃ³n
if image and st.button("ğŸ¯ Clasificar Imagen"):
    img_tensor = transform(image).unsqueeze(0)
    with torch.no_grad():
        outputs = model(img_tensor)
        _, predicted = torch.max(outputs, 1)

    predicted_class = class_names[predicted.item()]
    st.write(f"### ğŸ¨ PredicciÃ³n: {predicted_class}")
